# Claude Code Agentå®Ÿè£…ä»•æ§˜

å„PCä¸Šã§å‹•ä½œã™ã‚‹Claude Code Agentã®è©³ç´°å®Ÿè£…

## ğŸ—ï¸ Agent ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Claude Code Agent                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Task      â”‚  â”‚ Workspace   â”‚  â”‚   Claude    â”‚          â”‚
â”‚  â”‚ Executor    â”‚  â”‚  Manager    â”‚  â”‚ API Client  â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   GitHub    â”‚  â”‚    Git      â”‚  â”‚   Testing   â”‚          â”‚
â”‚  â”‚Integration  â”‚  â”‚  Handler    â”‚  â”‚   System    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚   Local     â”‚  â”‚   Config    â”‚  â”‚ Monitoring  â”‚          â”‚
â”‚  â”‚ Database    â”‚  â”‚ Manager     â”‚  â”‚   Client    â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â””â”€â”€ exceptions.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ task_executor.py
â”‚   â”‚   â”œâ”€â”€ workspace_manager.py
â”‚   â”‚   â”œâ”€â”€ claude_client.py
â”‚   â”‚   â”œâ”€â”€ github_client.py
â”‚   â”‚   â”œâ”€â”€ git_handler.py
â”‚   â”‚   â””â”€â”€ testing_system.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ task.py
â”‚   â”‚   â”œâ”€â”€ workspace.py
â”‚   â”‚   â””â”€â”€ result.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ routes.py
â”‚   â”‚   â””â”€â”€ middleware.py
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_utils.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â””â”€â”€ specialties/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ backend.py
â”‚       â”œâ”€â”€ frontend.py
â”‚       â”œâ”€â”€ testing.py
â”‚       â””â”€â”€ devops.py
â”œâ”€â”€ workspace/
â”œâ”€â”€ config/
â”œâ”€â”€ logs/
â”œâ”€â”€ tests/
â”œâ”€â”€ docker/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ ã‚³ã‚¢å®Ÿè£…

### 1. ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³

```python
# main.py
import asyncio
import signal
import uvicorn
from fastapi import FastAPI
from contextlib import asynccontextmanager

from src.core.config import get_settings
from src.core.logging import setup_logging
from src.services.task_executor import TaskExecutor
from src.services.workspace_manager import WorkspaceManager
from src.api.routes import router
from src.utils.metrics import setup_metrics

settings = get_settings()

class ClaudeCodeAgent:
    """Claude Code Agent ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.task_executor = TaskExecutor()
        self.workspace_manager = WorkspaceManager()
        self.running = False
        
    async def start(self):
        """Agenté–‹å§‹"""
        self.running = True
        
        # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹åˆæœŸåŒ–
        await self.workspace_manager.initialize()
        
        # Coordinatorã«ç™»éŒ²
        await self.register_with_coordinator()
        
        # ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆé–‹å§‹
        heartbeat_task = asyncio.create_task(self.heartbeat_loop())
        
        return heartbeat_task
    
    async def stop(self):
        """Agentåœæ­¢"""
        self.running = False
        await self.task_executor.cancel_all_tasks()
        await self.workspace_manager.cleanup()
    
    async def register_with_coordinator(self):
        """Coordinatorã¸ã®ç™»éŒ²"""
        import httpx
        
        registration_data = {
            "id": settings.AGENT_ID,
            "name": settings.AGENT_NAME,
            "hostname": settings.HOSTNAME,
            "ip_address": settings.IP_ADDRESS,
            "port": settings.PORT,
            "specialties": settings.SPECIALTIES,
            "capabilities": settings.CAPABILITIES,
            "max_concurrent_tasks": settings.MAX_CONCURRENT_TASKS,
            "cpu_cores": settings.CPU_CORES,
            "memory_gb": settings.MEMORY_GB,
            "disk_gb": settings.DISK_GB,
            "workspace_path": str(settings.WORKSPACE_PATH),
            "version": settings.VERSION
        }
        
        async with httpx.AsyncClient() as client:
            try:
                response = await client.post(
                    f"{settings.COORDINATOR_URL}/api/v1/agents",
                    json=registration_data,
                    headers={"Authorization": f"Bearer {settings.REGISTRATION_TOKEN}"},
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    print(f"Successfully registered with coordinator: {settings.AGENT_ID}")
                else:
                    print(f"Failed to register with coordinator: {response.status_code}")
                    
            except Exception as e:
                print(f"Error registering with coordinator: {e}")
    
    async def heartbeat_loop(self):
        """ãƒãƒ¼ãƒˆãƒ“ãƒ¼ãƒˆãƒ«ãƒ¼ãƒ—"""
        import httpx
        
        while self.running:
            try:
                status_data = {
                    "agent_id": settings.AGENT_ID,
                    "status": self.task_executor.get_status(),
                    "current_load": self.task_executor.get_load(),
                    "active_task_count": self.task_executor.get_active_task_count(),
                    "uptime": self.get_uptime(),
                    "last_task_completed_at": self.task_executor.get_last_completion_time()
                }
                
                async with httpx.AsyncClient() as client:
                    await client.put(
                        f"{settings.COORDINATOR_URL}/api/v1/agents/{settings.AGENT_ID}",
                        json=status_data,
                        headers={"Authorization": f"Bearer {settings.REGISTRATION_TOKEN}"},
                        timeout=10.0
                    )
                
                await asyncio.sleep(30)  # 30ç§’é–“éš”
                
            except Exception as e:
                print(f"Heartbeat error: {e}")
                await asyncio.sleep(60)
    
    def get_uptime(self) -> float:
        """ç¨¼åƒæ™‚é–“ã‚’å–å¾—"""
        # å®Ÿè£…çœç•¥
        return 0.0

# FastAPI ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
agent_instance = ClaudeCodeAgent()

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«"""
    
    # èµ·å‹•æ™‚
    setup_logging()
    setup_metrics()
    heartbeat_task = await agent_instance.start()
    
    app.state.agent = agent_instance
    
    yield
    
    # çµ‚äº†æ™‚
    await agent_instance.stop()
    heartbeat_task.cancel()

def create_app() -> FastAPI:
    """FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆ"""
    
    app = FastAPI(
        title=f"Claude Code Agent - {settings.AGENT_ID}",
        description=f"Claude Code Agent specialized in {', '.join(settings.SPECIALTIES)}",
        version=settings.VERSION,
        lifespan=lifespan
    )
    
    app.include_router(router)
    
    return app

app = create_app()

def signal_handler(signum, frame):
    """ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©"""
    print(f"Received signal {signum}, shutting down...")
    asyncio.create_task(agent_instance.stop())

if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    uvicorn.run(
        "main:app",
        host=settings.HOST,
        port=settings.PORT,
        reload=settings.DEBUG,
        log_level=settings.LOG_LEVEL.lower()
    )
```

### 2. è¨­å®šç®¡ç†

```python
# src/core/config.py
import os
import socket
from pathlib import Path
from typing import List, Optional
from pydantic_settings import BaseSettings
from pydantic import Field, validator

class AgentSettings(BaseSettings):
    """Agentè¨­å®š"""
    
    # AgentåŸºæœ¬æƒ…å ±
    AGENT_ID: str = Field(..., env="AGENT_ID")
    AGENT_NAME: str = Field(..., env="AGENT_NAME")
    VERSION: str = "1.0.0"
    
    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®š
    HOST: str = "0.0.0.0"
    PORT: int = 8081
    HOSTNAME: str = Field(default_factory=socket.gethostname)
    IP_ADDRESS: str = Field(..., env="IP_ADDRESS")
    
    # Coordinatorè¨­å®š
    COORDINATOR_URL: str = Field(..., env="COORDINATOR_URL")
    REGISTRATION_TOKEN: str = Field(..., env="REGISTRATION_TOKEN")
    
    # å°‚é–€æ€§è¨­å®š
    SPECIALTIES: List[str] = Field(..., env="SPECIALTIES")
    CAPABILITIES: List[str] = Field(..., env="CAPABILITIES") 
    
    # ãƒªã‚½ãƒ¼ã‚¹è¨­å®š
    MAX_CONCURRENT_TASKS: int = 3
    CPU_CORES: int = Field(..., env="CPU_CORES")
    MEMORY_GB: int = Field(..., env="MEMORY_GB")
    DISK_GB: int = Field(..., env="DISK_GB")
    
    # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹è¨­å®š
    WORKSPACE_PATH: Path = Field(..., env="WORKSPACE_PATH")
    WORKSPACE_CLEANUP_DAYS: int = 7
    WORKSPACE_MAX_SIZE_GB: int = 100
    
    # å¤–éƒ¨APIè¨­å®š
    ANTHROPIC_API_KEY: str = Field(..., env="ANTHROPIC_API_KEY")
    GITHUB_TOKEN: str = Field(..., env="GITHUB_TOKEN")
    
    # Gitè¨­å®š
    GIT_USER_NAME: str = Field(..., env="GIT_USER_NAME")
    GIT_USER_EMAIL: str = Field(..., env="GIT_USER_EMAIL")
    
    # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œè¨­å®š
    TASK_TIMEOUT_MINUTES: int = 60
    MAX_RETRY_ATTEMPTS: int = 3
    
    # ãƒ­ã‚°ãƒ»ç›£è¦–è¨­å®š
    LOG_LEVEL: str = "INFO"
    LOG_FILE: Optional[Path] = None
    DEBUG: bool = False
    METRICS_PORT: int = 9091
    
    @validator("SPECIALTIES", pre=True)
    def parse_specialties(cls, v):
        if isinstance(v, str):
            return [s.strip() for s in v.split(",")]
        return v
    
    @validator("CAPABILITIES", pre=True)
    def parse_capabilities(cls, v):
        if isinstance(v, str):
            return [c.strip() for c in v.split(",")]
        return v
    
    @validator("WORKSPACE_PATH", pre=True)
    def create_workspace_path(cls, v):
        path = Path(v)
        path.mkdir(parents=True, exist_ok=True)
        return path
    
    class Config:
        env_file = ".env"
        case_sensitive = True

def get_settings() -> AgentSettings:
    """è¨­å®šã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å–å¾—"""
    return AgentSettings()
```

### 3. Task Executor

```python
# src/services/task_executor.py
import asyncio
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from pathlib import Path

from src.core.config import get_settings
from src.models.task import Task, TaskResult, TaskStatus
from src.services.workspace_manager import WorkspaceManager
from src.services.claude_client import ClaudeClient
from src.services.github_client import GitHubClient
from src.services.git_handler import GitHandler
from src.services.testing_system import TestingSystem
from src.specialties import get_specialty_handler
from src.utils.metrics import task_metrics

logger = logging.getLogger(__name__)
settings = get_settings()

class TaskExecutor:
    """ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.workspace_manager = WorkspaceManager()
        self.claude_client = ClaudeClient()
        self.github_client = GitHubClient()
        self.git_handler = GitHandler()
        self.testing_system = TestingSystem()
        
        self.active_tasks: Dict[str, asyncio.Task] = {}
        self.task_results: Dict[str, TaskResult] = {}
        
    async def execute_task(self, task_data: Dict[str, Any]) -> TaskResult:
        """ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
        
        task = Task.from_dict(task_data)
        task_id = task.id
        
        logger.info(f"Starting task execution: {task_id}")
        
        # ä¸¦è¡Œå®Ÿè¡Œæ•°ãƒã‚§ãƒƒã‚¯
        if len(self.active_tasks) >= settings.MAX_CONCURRENT_TASKS:
            raise Exception("Maximum concurrent tasks reached")
        
        # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚’éåŒæœŸã§é–‹å§‹
        task_coroutine = self._execute_task_internal(task)
        async_task = asyncio.create_task(task_coroutine)
        self.active_tasks[task_id] = async_task
        
        try:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
            timeout_seconds = settings.TASK_TIMEOUT_MINUTES * 60
            result = await asyncio.wait_for(async_task, timeout=timeout_seconds)
            
            self.task_results[task_id] = result
            logger.info(f"Task {task_id} completed successfully")
            task_metrics.tasks_completed.inc()
            
            return result
            
        except asyncio.TimeoutError:
            logger.error(f"Task {task_id} timed out")
            async_task.cancel()
            result = TaskResult(
                task_id=task_id,
                status=TaskStatus.FAILED,
                error="Task execution timed out"
            )
            self.task_results[task_id] = result
            task_metrics.tasks_failed.inc()
            return result
            
        except Exception as e:
            logger.error(f"Task {task_id} failed: {e}")
            result = TaskResult(
                task_id=task_id,
                status=TaskStatus.FAILED,
                error=str(e)
            )
            self.task_results[task_id] = result
            task_metrics.tasks_failed.inc()
            return result
            
        finally:
            self.active_tasks.pop(task_id, None)
    
    async def _execute_task_internal(self, task: Task) -> TaskResult:
        """å†…éƒ¨ã‚¿ã‚¹ã‚¯å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯"""
        
        start_time = datetime.now()
        
        try:
            # 1. ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹æº–å‚™
            workspace = await self.workspace_manager.prepare_workspace(task)
            logger.info(f"Workspace prepared: {workspace.path}")
            
            # 2. ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
            repo_path = await self.git_handler.clone_repository(
                workspace.path, task.github_repository
            )
            logger.info(f"Repository cloned: {repo_path}")
            
            # 3. ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æ
            codebase_analysis = await self._analyze_codebase(repo_path, task)
            logger.info(f"Codebase analyzed: {len(codebase_analysis.get('files', []))} files")
            
            # 4. å°‚é–€æ€§ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã«ã‚ˆã‚‹äº‹å‰å‡¦ç†
            specialty_handler = get_specialty_handler(settings.SPECIALTIES[0])
            if specialty_handler:
                await specialty_handler.pre_process(workspace, task)
            
            # 5. Claude APIã§å®Ÿè£…ç”Ÿæˆ
            implementation = await self.claude_client.generate_implementation(
                task, codebase_analysis, workspace
            )
            logger.info(f"Implementation generated: {len(implementation.changes)} changes")
            
            # 6. ã‚³ãƒ¼ãƒ‰å¤‰æ›´é©ç”¨
            applied_changes = await self._apply_code_changes(
                repo_path, implementation.changes
            )
            logger.info(f"Applied {len(applied_changes)} code changes")
            
            # 7. ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_results = await self.testing_system.run_tests(repo_path, task)
            logger.info(f"Tests completed: {test_results.summary}")
            
            # 8. å°‚é–€æ€§ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã«ã‚ˆã‚‹å¾Œå‡¦ç†
            if specialty_handler:
                await specialty_handler.post_process(workspace, task, test_results)
            
            # 9. Gitæ“ä½œï¼ˆãƒ–ãƒ©ãƒ³ãƒä½œæˆãƒ»ã‚³ãƒŸãƒƒãƒˆï¼‰
            branch_name = f"claude-{settings.AGENT_ID}-task-{task.id}"
            await self.git_handler.create_branch_and_commit(
                repo_path, branch_name, applied_changes, task
            )
            logger.info(f"Changes committed to branch: {branch_name}")
            
            # 10. Pull Requestä½œæˆ
            pr_url = await self.github_client.create_pull_request(
                task.github_repository, branch_name, task, implementation, test_results
            )
            logger.info(f"Pull Request created: {pr_url}")
            
            # 11. å®Ÿè¡Œæ™‚é–“è¨ˆç®—
            execution_time = (datetime.now() - start_time).total_seconds()
            
            return TaskResult(
                task_id=task.id,
                status=TaskStatus.COMPLETED,
                pr_url=pr_url,
                branch_name=branch_name,
                changes_applied=applied_changes,
                test_results=test_results,
                execution_time=execution_time,
                agent_id=settings.AGENT_ID
            )
            
        except Exception as e:
            logger.error(f"Task execution failed: {e}", exc_info=True)
            raise
            
        finally:
            # ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆè¨­å®šã«ã‚ˆã‚‹ï¼‰
            if not settings.DEBUG:
                await self.workspace_manager.cleanup_workspace(task.id)
    
    async def _analyze_codebase(self, repo_path: Path, task: Task) -> Dict[str, Any]:
        """ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹åˆ†æ"""
        
        analysis = {
            "repository_path": str(repo_path),
            "files": [],
            "structure": {},
            "dependencies": {},
            "test_structure": {},
            "relevant_files": []
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ åˆ†æ
        for file_path in repo_path.rglob("*"):
            if file_path.is_file() and not self._should_ignore_file(file_path):
                relative_path = file_path.relative_to(repo_path)
                analysis["files"].append(str(relative_path))
        
        # ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
        analysis["relevant_files"] = await self._identify_relevant_files(
            repo_path, task, analysis["files"]
        )
        
        # ä¾å­˜é–¢ä¿‚åˆ†æ
        analysis["dependencies"] = await self._analyze_dependencies(repo_path)
        
        # ãƒ†ã‚¹ãƒˆæ§‹é€ åˆ†æ
        analysis["test_structure"] = await self._analyze_test_structure(repo_path)
        
        return analysis
    
    def _should_ignore_file(self, file_path: Path) -> bool:
        """ç„¡è¦–ã™ã¹ããƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯"""
        ignore_patterns = [
            ".*",  # éš ã—ãƒ•ã‚¡ã‚¤ãƒ«
            "__pycache__",
            "node_modules",
            ".git",
            "*.pyc",
            "*.log",
            "*.tmp"
        ]
        
        for pattern in ignore_patterns:
            if file_path.match(pattern) or any(part.startswith('.') for part in file_path.parts):
                return True
        return False
    
    async def _identify_relevant_files(self, repo_path: Path, task: Task, all_files: List[str]) -> List[str]:
        """ã‚¿ã‚¹ã‚¯ã«é–¢é€£ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š"""
        
        relevant_files = []
        
        # Issueç•ªå·ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        if task.github_issue_number:
            # æœ€è¿‘ã®ã‚³ãƒŸãƒƒãƒˆã§Issueç•ªå·ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            # å®Ÿè£…çœç•¥
            pass
        
        # ã‚¿ã‚¹ã‚¯ã‚¿ã‚¤ãƒˆãƒ«/èª¬æ˜ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        keywords = self._extract_keywords_from_task(task)
        for file_path in all_files:
            if any(keyword.lower() in file_path.lower() for keyword in keywords):
                relevant_files.append(file_path)
        
        # å°‚é–€æ€§ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«å„ªå…ˆé †ä½ä»˜ã‘
        specialty_files = self._filter_files_by_specialty(all_files, settings.SPECIALTIES)
        relevant_files.extend(specialty_files)
        
        return list(set(relevant_files))  # é‡è¤‡é™¤å»
    
    def _extract_keywords_from_task(self, task: Task) -> List[str]:
        """ã‚¿ã‚¹ã‚¯ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        import re
        
        text = f"{task.title} {task.description}"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã€ã‚¯ãƒ©ã‚¹åã€é–¢æ•°åã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
        patterns = [
            r'\b\w+\.py\b',  # Python ãƒ•ã‚¡ã‚¤ãƒ«
            r'\b\w+\.ts\b',  # TypeScript ãƒ•ã‚¡ã‚¤ãƒ«
            r'\b\w+\.tsx\b', # TypeScript React ãƒ•ã‚¡ã‚¤ãƒ«
            r'\bclass\s+(\w+)',  # ã‚¯ãƒ©ã‚¹å
            r'\bfunction\s+(\w+)',  # é–¢æ•°å
            r'\bdef\s+(\w+)',  # Python é–¢æ•°å
        ]
        
        keywords = []
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            keywords.extend(matches)
        
        return keywords
    
    def _filter_files_by_specialty(self, files: List[str], specialties: List[str]) -> List[str]:
        """å°‚é–€æ€§ã«åŸºã¥ããƒ•ã‚¡ã‚¤ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"""
        
        specialty_patterns = {
            "backend": [r".*\.py$", r".*/api/.*", r".*/services/.*", r".*/models/.*"],
            "frontend": [r".*\.tsx?$", r".*\.jsx?$", r".*/components/.*", r".*/pages/.*"],
            "testing": [r".*test.*\.py$", r".*\.test\.ts$", r".*\.spec\.ts$"],
            "devops": [r".*\.yml$", r".*\.yaml$", r"Dockerfile", r"docker-compose.*"],
        }
        
        relevant_files = []
        for specialty in specialties:
            if specialty in specialty_patterns:
                patterns = specialty_patterns[specialty]
                for file_path in files:
                    if any(re.match(pattern, file_path) for pattern in patterns):
                        relevant_files.append(file_path)
        
        return relevant_files
    
    async def _apply_code_changes(self, repo_path: Path, changes: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ã‚³ãƒ¼ãƒ‰å¤‰æ›´ã®é©ç”¨"""
        
        applied_changes = []
        
        for change in changes:
            try:
                file_path = repo_path / change["file_path"]
                
                if change["action"] == "create":
                    # æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                    file_path.parent.mkdir(parents=True, exist_ok=True)
                    file_path.write_text(change["content"], encoding="utf-8")
                    applied_changes.append(change)
                    
                elif change["action"] == "modify":
                    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿®æ­£
                    if file_path.exists():
                        file_path.write_text(change["content"], encoding="utf-8")
                        applied_changes.append(change)
                    else:
                        logger.warning(f"File to modify does not exist: {file_path}")
                        
                elif change["action"] == "delete":
                    # ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    if file_path.exists():
                        file_path.unlink()
                        applied_changes.append(change)
                    else:
                        logger.warning(f"File to delete does not exist: {file_path}")
                
            except Exception as e:
                logger.error(f"Failed to apply change to {change['file_path']}: {e}")
        
        return applied_changes
    
    async def cancel_task(self, task_id: str) -> bool:
        """ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        if task_id in self.active_tasks:
            task = self.active_tasks[task_id]
            task.cancel()
            
            try:
                await task
            except asyncio.CancelledError:
                pass
            
            self.active_tasks.pop(task_id, None)
            logger.info(f"Task {task_id} cancelled")
            return True
        
        return False
    
    async def cancel_all_tasks(self):
        """å…¨ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        for task_id in list(self.active_tasks.keys()):
            await self.cancel_task(task_id)
    
    def get_status(self) -> str:
        """AgentçŠ¶æ…‹ã‚’å–å¾—"""
        if len(self.active_tasks) == 0:
            return "idle"
        elif len(self.active_tasks) < settings.MAX_CONCURRENT_TASKS:
            return "busy"
        else:
            return "overloaded"
    
    def get_load(self) -> float:
        """è² è·ç‡ã‚’å–å¾—"""
        return len(self.active_tasks) / settings.MAX_CONCURRENT_TASKS
    
    def get_active_task_count(self) -> int:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ã‚¹ã‚¯æ•°ã‚’å–å¾—"""
        return len(self.active_tasks)
    
    def get_last_completion_time(self) -> Optional[datetime]:
        """æœ€å¾Œã®ã‚¿ã‚¹ã‚¯å®Œäº†æ™‚åˆ»ã‚’å–å¾—"""
        # å®Ÿè£…çœç•¥
        return None
```

### 4. Workspace Manager

```python
# src/services/workspace_manager.py
import shutil
import asyncio
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional

from src.core.config import get_settings
from src.models.workspace import TaskWorkspace
from src.models.task import Task

settings = get_settings()

class WorkspaceManager:
    """ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.base_path = settings.WORKSPACE_PATH
        self.base_path.mkdir(parents=True, exist_ok=True)
    
    async def initialize(self):
        """ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹åˆæœŸåŒ–"""
        
        # åŸºæœ¬ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        (self.base_path / "tasks").mkdir(exist_ok=True)
        (self.base_path / "shared").mkdir(exist_ok=True)
        (self.base_path / "logs").mkdir(exist_ok=True)
        (self.base_path / "cache").mkdir(exist_ok=True)
        (self.base_path / "templates").mkdir(exist_ok=True)
        
        # å¤ã„ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await self.cleanup_old_workspaces()
    
    async def prepare_workspace(self, task: Task) -> TaskWorkspace:
        """ã‚¿ã‚¹ã‚¯å°‚ç”¨ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’æº–å‚™"""
        
        # ã‚¿ã‚¹ã‚¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        task_path = self.base_path / "tasks" / f"task-{task.id}"
        task_path.mkdir(parents=True, exist_ok=True)
        
        # ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        (task_path / "repository").mkdir(exist_ok=True)
        (task_path / "implementation").mkdir(exist_ok=True)
        (task_path / "tests").mkdir(exist_ok=True)
        (task_path / "logs").mkdir(exist_ok=True)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        metadata_file = task_path / "metadata.json"
        metadata = {
            "task_id": task.id,
            "title": task.title,
            "created_at": datetime.now().isoformat(),
            "agent_id": settings.AGENT_ID,
            "specialties": settings.SPECIALTIES
        }
        
        import json
        metadata_file.write_text(json.dumps(metadata, indent=2))
        
        return TaskWorkspace(
            task_id=task.id,
            path=task_path,
            repository_path=task_path / "repository",
            implementation_path=task_path / "implementation",
            tests_path=task_path / "tests",
            logs_path=task_path / "logs"
        )
    
    async def cleanup_workspace(self, task_id: str):
        """ç‰¹å®šã‚¿ã‚¹ã‚¯ã®ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        
        task_path = self.base_path / "tasks" / f"task-{task_id}"
        
        if task_path.exists():
            try:
                shutil.rmtree(task_path)
                print(f"Cleaned up workspace for task {task_id}")
            except Exception as e:
                print(f"Failed to cleanup workspace for task {task_id}: {e}")
    
    async def cleanup_old_workspaces(self):
        """å¤ã„ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        
        cutoff_date = datetime.now() - timedelta(days=settings.WORKSPACE_CLEANUP_DAYS)
        tasks_dir = self.base_path / "tasks"
        
        if not tasks_dir.exists():
            return
        
        for task_dir in tasks_dir.iterdir():
            if task_dir.is_dir():
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ä½œæˆæ—¥æ™‚ã‚’ç¢ºèª
                metadata_file = task_dir / "metadata.json"
                
                if metadata_file.exists():
                    try:
                        import json
                        metadata = json.loads(metadata_file.read_text())
                        created_at = datetime.fromisoformat(metadata["created_at"])
                        
                        if created_at < cutoff_date:
                            shutil.rmtree(task_dir)
                            print(f"Cleaned up old workspace: {task_dir.name}")
                            
                    except Exception as e:
                        print(f"Error processing workspace {task_dir.name}: {e}")
                else:
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ™‚åˆ»ã§åˆ¤æ–­
                    if task_dir.stat().st_mtime < cutoff_date.timestamp():
                        shutil.rmtree(task_dir)
                        print(f"Cleaned up old workspace: {task_dir.name}")
    
    async def get_workspace_usage(self) -> dict:
        """ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½¿ç”¨é‡ã‚’å–å¾—"""
        
        def get_dir_size(path: Path) -> int:
            """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚µã‚¤ã‚ºã‚’å–å¾—"""
            total = 0
            try:
                for item in path.rglob("*"):
                    if item.is_file():
                        total += item.stat().st_size
            except (OSError, PermissionError):
                pass
            return total
        
        usage = {
            "total_size_bytes": get_dir_size(self.base_path),
            "total_size_gb": get_dir_size(self.base_path) / (1024**3),
            "task_count": len(list((self.base_path / "tasks").iterdir())) if (self.base_path / "tasks").exists() else 0,
            "max_size_gb": settings.WORKSPACE_MAX_SIZE_GB,
            "usage_percentage": 0.0
        }
        
        if settings.WORKSPACE_MAX_SIZE_GB > 0:
            usage["usage_percentage"] = usage["total_size_gb"] / settings.WORKSPACE_MAX_SIZE_GB * 100
        
        return usage
    
    async def ensure_disk_space(self, required_gb: float = 10.0) -> bool:
        """å¿…è¦ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ã‚’ç¢ºä¿"""
        
        usage = await self.get_workspace_usage()
        available_gb = settings.WORKSPACE_MAX_SIZE_GB - usage["total_size_gb"]
        
        if available_gb >= required_gb:
            return True
        
        # å¤ã„ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ã‚’ç©æ¥µçš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        print(f"Disk space low ({available_gb:.1f}GB available), cleaning up...")
        
        # ã‚ˆã‚ŠçŸ­ã„æœŸé–“ã§ã®å¼·åˆ¶ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        cutoff_date = datetime.now() - timedelta(days=3)
        tasks_dir = self.base_path / "tasks"
        
        cleaned_space = 0.0
        for task_dir in tasks_dir.iterdir():
            if task_dir.is_dir():
                size_before = self.get_dir_size(task_dir) / (1024**3)
                
                metadata_file = task_dir / "metadata.json"
                if metadata_file.exists():
                    try:
                        import json
                        metadata = json.loads(metadata_file.read_text())
                        created_at = datetime.fromisoformat(metadata["created_at"])
                        
                        if created_at < cutoff_date:
                            shutil.rmtree(task_dir)
                            cleaned_space += size_before
                            print(f"Emergency cleanup: {task_dir.name} ({size_before:.1f}GB)")
                            
                            if cleaned_space >= required_gb:
                                break
                                
                    except Exception:
                        pass
        
        # å†ãƒã‚§ãƒƒã‚¯
        usage = await self.get_workspace_usage()
        available_gb = settings.WORKSPACE_MAX_SIZE_GB - usage["total_size_gb"]
        
        return available_gb >= required_gb
```

### 5. Claude Client

```python
# src/services/claude_client.py
import logging
from typing import Dict, Any, List
from anthropic import Anthropic

from src.core.config import get_settings
from src.models.task import Task
from src.models.workspace import TaskWorkspace

logger = logging.getLogger(__name__)
settings = get_settings()

class ClaudeClient:
    """Claude API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.client = Anthropic(api_key=settings.ANTHROPIC_API_KEY)
        self.model = "claude-3-sonnet-20240229"
    
    async def generate_implementation(
        self, 
        task: Task, 
        codebase_analysis: Dict[str, Any],
        workspace: TaskWorkspace
    ) -> 'ImplementationResult':
        """å®Ÿè£…ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ"""
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        system_prompt = self._build_system_prompt()
        user_prompt = self._build_user_prompt(task, codebase_analysis)
        
        try:
            # Claude APIå‘¼ã³å‡ºã—
            message = self.client.messages.create(
                model=self.model,
                max_tokens=4000,
                system=system_prompt,
                messages=[{
                    "role": "user",
                    "content": user_prompt
                }]
            )
            
            response_text = message.content[0].text
            logger.info(f"Claude API response length: {len(response_text)} characters")
            
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ
            implementation = self._parse_implementation_response(response_text)
            
            return implementation
            
        except Exception as e:
            logger.error(f"Claude API error: {e}")
            raise
    
    def _build_system_prompt(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        
        return f"""ã‚ãªãŸã¯å°‚é–€çš„ãªã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢é–‹ç™ºè€…ã§ã™ã€‚

# Agentæƒ…å ±
- Agent ID: {settings.AGENT_ID}
- å°‚é–€åˆ†é‡: {', '.join(settings.SPECIALTIES)}
- èƒ½åŠ›: {', '.join(settings.CAPABILITIES)}

# é–‹ç™ºæ–¹é‡
1. Test-Driven Development (TDD) ã«å¾“ã£ã¦å®Ÿè£…
2. å‹å®‰å…¨æ€§ã‚’é‡è¦–ï¼ˆTypeScript/Pythonå‹ãƒ’ãƒ³ãƒˆï¼‰
3. æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã«åˆã‚ã›ã‚‹
4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹ã«å¾“ã†
5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’è€ƒæ…®ã—ãŸå®Ÿè£…

# å‡ºåŠ›å½¢å¼
å®Ÿè£…çµæœã‚’JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

```json
{{
  "summary": "å®Ÿè£…ã®æ¦‚è¦èª¬æ˜",
  "approach": "æ¡ç”¨ã—ãŸã‚¢ãƒ—ãƒ­ãƒ¼ãƒã®èª¬æ˜",
  "changes": [
    {{
      "action": "create|modify|delete",
      "file_path": "ç›¸å¯¾ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
      "content": "ãƒ•ã‚¡ã‚¤ãƒ«ã®å…¨å†…å®¹",
      "description": "å¤‰æ›´ã®èª¬æ˜"
    }}
  ],
  "test_strategy": "ãƒ†ã‚¹ãƒˆæˆ¦ç•¥ã®èª¬æ˜",
  "dependencies": ["æ–°ã—ãå¿…è¦ãªä¾å­˜é–¢ä¿‚"],
  "notes": "å®Ÿè£…ã«é–¢ã™ã‚‹æ³¨æ„äº‹é …"
}}
```

ã‚³ãƒ¼ãƒ‰ã¯å¿…ãšå‹•ä½œã™ã‚‹ã‚‚ã®ã‚’ç”Ÿæˆã—ã€æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãŒãªã„ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"""
    
    def _build_user_prompt(self, task: Task, codebase_analysis: Dict[str, Any]) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        
        relevant_files_content = self._get_relevant_files_content(codebase_analysis)
        
        return f"""# ã‚¿ã‚¹ã‚¯è©³ç´°

## Issueæƒ…å ±
- Issueç•ªå·: #{task.github_issue_number}
- ã‚¿ã‚¤ãƒˆãƒ«: {task.title}
- èª¬æ˜: {task.description}
- å„ªå…ˆåº¦: {task.priority}
- è¦ä»¶: {', '.join(task.requirements or [])}

## ãƒªãƒã‚¸ãƒˆãƒªæƒ…å ±
- ãƒªãƒã‚¸ãƒˆãƒª: {task.github_repository}
- ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(codebase_analysis.get('files', []))}
- é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(codebase_analysis.get('relevant_files', []))}

## ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ§‹é€ 
```
{self._format_codebase_structure(codebase_analysis)}
```

## é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹
{relevant_files_content}

## ä¾å­˜é–¢ä¿‚æƒ…å ±
{self._format_dependencies(codebase_analysis.get('dependencies', {}))}

## ãƒ†ã‚¹ãƒˆæ§‹é€ 
{self._format_test_structure(codebase_analysis.get('test_structure', {}))}

# å®Ÿè£…è¦æ±‚

ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€Issue #{task.github_issue_number} ã®è¦æ±‚ã‚’æº€ãŸã™å®Ÿè£…ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ç‰¹ã«ä»¥ä¸‹ã®ç‚¹ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š
1. æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«ã¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¾“ã†
2. é©åˆ‡ãªãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã‚’å«ã‚ã‚‹
3. å‹å®‰å…¨æ€§ã‚’ä¿ã¤
4. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’è€ƒæ…®ã™ã‚‹
5. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«é…æ…®ã™ã‚‹

å°‚é–€åˆ†é‡ï¼ˆ{', '.join(settings.SPECIALTIES)}ï¼‰ã®è¦³ç‚¹ã‹ã‚‰æœ€é©ãªå®Ÿè£…ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""
    
    def _get_relevant_files_content(self, codebase_analysis: Dict[str, Any]) -> str:
        """é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’å–å¾—"""
        
        # å®Ÿè£…çœç•¥ - å®Ÿéš›ã«ã¯é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚“ã§æ•´å½¢
        relevant_files = codebase_analysis.get('relevant_files', [])
        
        if not relevant_files:
            return "é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ãŒç‰¹å®šã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        content = ""
        for file_path in relevant_files[:10]:  # æœ€å¤§10ãƒ•ã‚¡ã‚¤ãƒ«
            content += f"\n## {file_path}\n```\n[ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹]\n```\n"
        
        return content
    
    def _format_codebase_structure(self, codebase_analysis: Dict[str, Any]) -> str:
        """ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹æ§‹é€ ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        
        files = codebase_analysis.get('files', [])
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’æ§‹ç¯‰
        structure = {}
        for file_path in files[:50]:  # æœ€å¤§50ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º
            parts = file_path.split('/')
            current = structure
            for part in parts[:-1]:
                if part not in current:
                    current[part] = {}
                current = current[part]
            current[parts[-1]] = None
        
        return self._dict_to_tree_string(structure)
    
    def _dict_to_tree_string(self, d: dict, prefix: str = "") -> str:
        """è¾æ›¸ã‚’ãƒ„ãƒªãƒ¼æ§‹é€ ã®æ–‡å­—åˆ—ã«å¤‰æ›"""
        
        result = ""
        items = list(d.items())
        
        for i, (key, value) in enumerate(items):
            is_last = i == len(items) - 1
            current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            result += f"{prefix}{current_prefix}{key}\n"
            
            if isinstance(value, dict):
                next_prefix = prefix + ("    " if is_last else "â”‚   ")
                result += self._dict_to_tree_string(value, next_prefix)
        
        return result
    
    def _format_dependencies(self, dependencies: Dict[str, Any]) -> str:
        """ä¾å­˜é–¢ä¿‚æƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        
        if not dependencies:
            return "ä¾å­˜é–¢ä¿‚æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        result = ""
        for key, value in dependencies.items():
            result += f"- {key}: {value}\n"
        
        return result
    
    def _format_test_structure(self, test_structure: Dict[str, Any]) -> str:
        """ãƒ†ã‚¹ãƒˆæ§‹é€ ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        
        if not test_structure:
            return "ãƒ†ã‚¹ãƒˆæ§‹é€ æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
        
        # å®Ÿè£…çœç•¥
        return "ãƒ†ã‚¹ãƒˆæ§‹é€ : [ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆæ¸ˆã¿]"
    
    def _parse_implementation_response(self, response: str) -> 'ImplementationResult':
        """Claude APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è§£æ"""
        
        import json
        import re
        
        # JSONéƒ¨åˆ†ã‚’æŠ½å‡º
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
        
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                
                from src.models.result import ImplementationResult
                return ImplementationResult(
                    summary=data.get('summary', ''),
                    approach=data.get('approach', ''),
                    changes=data.get('changes', []),
                    test_strategy=data.get('test_strategy', ''),
                    dependencies=data.get('dependencies', []),
                    notes=data.get('notes', '')
                )
                
            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse JSON response: {e}")
                raise
        
        else:
            logger.error("No JSON found in Claude response")
            raise ValueError("Invalid response format from Claude API")
```

ã“ã®å®Ÿè£…ã«ã‚ˆã‚Šã€å„Claude Code Agentã¯Coordinatorã‹ã‚‰å—ã‘å–ã£ãŸã‚¿ã‚¹ã‚¯ã‚’å°‚é–€æ€§ã‚’æ´»ã‹ã—ã¦åŠ¹ç‡çš„ã«å®Ÿè¡Œã§ãã¾ã™ã€‚æ¬¡ã¯GitHubçµ±åˆã‚„Deploymenté–¢é€£ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã™ã‹ï¼Ÿ